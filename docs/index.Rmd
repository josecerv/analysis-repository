---
title: "Rmarkdown Repository"
date: 'Updated `r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document:
    toc: yes
    toc_depth: 3
    fig_caption: true
header-includes:
  \renewcommand{\contentsname}{Items}
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE,
	results = "hide"
)
library(aod)
library(car)
library(lmtest)
library(tidyverse)
library(gridExtra)
library(readxl)
library(dplyr)
library(tidyr)
library(janitor)
library(pander)
library(ggsignif)
library(extrafont)
library(googlesheets4)
library(stargazer)
library(sandwich)
library(lmtest)
library(ggcorrplot)
library(ggpubr)
```

# Data Simulation

```{r echo=TRUE, results="markdown"}
library(simstudy)

## define variables within the defData function
### dist = distribution
### formula = mean or probability
### variance = variance
### varname = variable name
def <- defData(varname = "age", dist = "normal", formula = 10,
    variance = 2)
def <- defData(def, varname = "female", dist = "binary",
    formula = "-2 + age * 0.1", link = "logit")
def <- defData(def, varname = "visits", dist = "poisson",
    formula = "1.5 - 0.2 * age + 0.5 * female", link = "log")
def <- defData(def, varname = "shots", dist = "poisson",
    formula = 3, variance = 1.5)
set.seed(123)
dd <- genData(1000, def)
head(dd, 20)
mean(dd$age) # should be near 10
sd(dd$age)^2 # should be close to 2
mean(dd$shots) # should be 3

## assigning treatment/control

## nTrt = number of treatments
## ratio = probabilities

study1 <- trtAssign(dd, nTrt = 2, balanced = TRUE, grpName = "TRT", ratio = c(0.5, 0.5))
head(study1, 10)


```



# Data cleaning

## Filtering
## Merging, Joining
## Mutating (efficiently)
## Validation (screening)
## Recoding

# Tables, Visualizations

## Demographics
## Balance Checks
## Bar Plots/Histograms
## Correlation Matrices

```{r echo=TRUE, results="markdown"}
## create likert scale (7 Qs, 1-7 scale)
def <- defRepeat(nVars = 7, prefix = "IVL", formula = "1/7;1/3;1/3;1/7;1/1;1/1; 1/1", dist = "categorical")
def <- defRepeat(def, nVars = 3, prefix = "IVN", formula = 50, variance = 10, dist = "normal")
df1 <- genData(100, def)
df1 <- trtAssign(df1, nTrt = 4, balanced = TRUE, grpName = "TRT", ratio = c(0.25, 0.25, 0.25, 0.25))
df1 <- df1 |> 
  mutate(TRT = as.factor(TRT))
head(df1)

createCorMatrix <- function(data, sides = 1){

    
  
  ## subset Likert items
  likert_df <- df1 |> 
  select(contains("IVL"))
corr_likert <- round(cor(likert_df), 1)

  ## subset continuous items
  continuous_df <- df1 |> 
  select(contains("IVN"))
corr_cont <- round(cor(continuous_df), 1)

  ## store all IVs
  iv_df <- df1 |> 
  select(contains("IV"))
corr_iv <- round(cor(iv_df), 1)

  ## make correlations plots of each type
  ## only Likert IVs, only Continuous IVs, all IVs
likert_plot <- ggcorrplot(corr_likert, hc.order = F, type = "lower",
   outline.col = "black",
   ggtheme = ggplot2::theme_gray,
   colors = c("#6D9EC1", "white", "#E46726"))+
  ggtitle("Correlation of Likert Items")

cont_plot <- ggcorrplot(corr_cont, hc.order = F, type = "lower",
   outline.col = "black",
   ggtheme = ggplot2::theme_gray,
   colors = c("#6D9EC1", "white", "#E46726"))+
  ggtitle("Correlation of Continuous Items")

iv_plot <- ggcorrplot(corr_iv, hc.order = F, type = "lower",
   outline.col = "black",
   ggtheme = ggplot2::theme_gray,
   colors = c("#6D9EC1", "white", "#E46726"))+
  ggtitle("Correlation of All Items")

  if(sides > 1){
    return(list(likert_plot, cont_plot, iv_plot))
    
  }
  else{
    print(likert_plot)
    print(cont_plot) 
    print(iv_plot)

  }

  
}
createCorMatrixCond <- function(data, conditions = 2){
  
  plot_list = list()
  
  for(i in seq_len(conditions)){
  cond <- levels(data$TRT)[i]
  
  assign(paste0(cond, "_df"),
         data |> 
           filter(TRT == cond))
  matrices <- get(paste0(cond, "_df"))
  plots <- createCorMatrix(matrices,2)
  group_plot <- ggarrange(plotlist = plots, legend = "right", ncol = 3)+
    annotate(geom = "text", label = paste0("Condition ",cond, " Plot"), y = 0.85, x = 0.5, size = 10)
  ggsave(paste0("Condition ",cond, " Plot.pdf"), group_plot, width = 17, height = 12)
  print(group_plot)
  }
}

createCorMatrix(df1)
createCorMatrixCond(df1, conditions = length(levels(df1$TRT)))


```

## Tables
## Stargazer

# Analysis

## Linear Models (OLS, GLM)

### Robust Standard Errors in R

```{r echo=TRUE}
# robust standard errors
se_robust <- function(model)
  coeftest(model, vcov = vcovHC(model, "HC0")) 
```

### Modular Regression formulas

```{r echo=TRUE}
# initialize data
y = rep(seq(0,1), 5)
x1 = runif(10)
x2 = runif(10)
x3 = runif(10)
## or you can create a bunch of variables at a time
for(i in 1:25){
  assign(paste0("x", i), runif(10))
}
# create a vector of your covariates, control, no controls, etc.
covariates <- paste0("x", 1:3)


# create a formula, or you can loop create various formulas as above
formula1 <- as.formula(paste("y ~ ", paste(covariates, collapse= "+")))

# condensed formula
formula2 <- as.formula(paste("y ~ ", paste(covariates[1:2], collapse= "+")))
# run regression
lm(formula1)
lm(formula2)

```
### Multivariate Regression
```{r Multivariate Regression}
#Mreg <-lm(cbind(DV, IV1, IV2)~ Control1 + Control2, data = data)
#summary(Mreg)
```

### Hierarchical Regression
```{r Hierarchical Regression}
# Model1 <- lm(DV~IV1 + IV2, data = data)
# Model2 <- lm(DV~IV1 + IV2 + Control1 + Control2, data = data)
# Model3 <- lm(DV~IV1 + IV2 + Control1 + Control2 + Control3 + Control4, data = data)
# Model4 <- lm(DV~IV1 + IV2 + Control1 + Control2 + Control3 + Control4 + Control5, data = data)
```

## Mediation
## Power Analysis

```{r echo=TRUE}

## create power calculations for two-sample proportions
## sample needed for various raw treatment effect
## p1 = baseline treatment, p1+i = treatment increase
p1 <- c(0.01, 0.02, 0.024, 0.03, 0.04, 0.05)
p1 <- p1
p2 <- p1*1.02
p3 <- p1*1.05
p4 <- p1*1.10
p5 <- p1*1.15
p6 <- p1*1.20
p7 <- p1*1.25
n1 <- c()
n2 <- c()
n3 <- c()
n4 <- c()
n5 <- c()
n6 <- c()

for(i in 1:length(p2)){
  n1[i] <- power.prop.test(p1=p1[i], p2=p2[i],power=0.9)$n
  n2[i] <- power.prop.test(p1=p1[i], p2=p3[i],power=0.9)$n
  n3[i] <- power.prop.test(p1=p1[i], p2=p4[i],power=0.9)$n
  n4[i] <- power.prop.test(p1=p1[i], p2=p5[i],power=0.9)$n
  n5[i] <- power.prop.test(p1=p1[i], p2=p6[i],power=0.9)$n
  n6[i] <- power.prop.test(p1=p1[i], p2=p7[i],power=0.9)$n
}

data.frame(Baseline = paste0(round(p1*100,2), '%'),
           `1_Increase` = paste0(round(p2*100,2), '%'),
           N1 = n1,
           `2_Increase` = paste0(round(p3*100,2), '%'),
           N2 = n2,
           `3_Increase` = paste0(round(p4*100,2), '%'),
           N3 = n3) %>% 
  rename(`2% Increase` = `X1_Increase`,
         `5% Increase` = `X2_Increase`,
         `N @ 2%` = N1,
         `N @ 5%` = N2,
         `10% Increase` = `X3_Increase`,
         `N @ 10%` = N3) |> 
  pandoc.table(caption = "Sample Size needed for alpha = 0.05 at power = 0.9 w/ 2%, 5%, and 10% increases")

```

## Bootstrapping, Simulation
## Model Estimations (coefficient testing)
## Seemingly Unrelated Regressions (testing other models)

# Functional programming

## Programming with dply verbs
## Function factories
## Applications for Analysis
### Cleaning
### Visualization
### Tables

```{r echo=TRUE, results="markdown"}
 power_n <- function(exp) {
   function(x) {
     x ^ exp
   }
 }

 names <- list(
   square = 2,
   cube = 3,
   root = 1/2,
   cuberoot = 1/3,
   reciprocal = -1
 )
 funs <- purrr::map(names, power_n)

 funs$root(64)
 funs$square(64)
 funs$cuberoot(64)
```